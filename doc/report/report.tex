\documentclass[11pt,twocolumn,twoside,paper=a4]{IEEEtran}
\usepackage{amsmath}
% Swap the comments on the two below lines to toggle the geometry view of the margins, etc...
%\usepackage[margin=0.75in,headheight=0.45in,showframe]{geometry}
\usepackage[margin=0.75in,headheight=0.45in]{geometry}
\usepackage[pdftex]{epsfig}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{fancyhdr}
\usepackage[utf8]{inputenc}
\include{graphicsx}
\usepackage{graphicx}
\usepackage{subcaption}

\pagestyle{fancy}
%\renewcommand{\headrulewidth}{0pt}
\renewcommand{\footrulewidth}{0pt}
\rhead{\includegraphics[height=0.4in]{../images/uos.pdf}}
\fancyhead[LO]{\sc Upscaling GAN} % shorter form of title to fit in space
\fancyhead[LE]{\sc ben Ahmed, Hoffmann, Zielinski} % author list or et al., to fit in space
\chead{}
\cfoot{}

\begin{document}
\title{\vspace{0.2in}\sc Upscaling images using a Generative Adversarial Network}
\author{Martin ben Ahmed$^{1,2}$\thanks{$^1$Institute of Computer Science, University of Osnabr√ºck $^2$mbenahmed@uos.de $^3$pahoffmann@uos.de $^4$szielinski@uos.de}, Patrick Hoffmann$^{1,3}$, Sebastian Zielinski$^{1,4}$}

\maketitle
\thispagestyle{fancy}
\begin{abstract}
New state of the art neural network architectures and ever increasing computational resources
offer a large potential for new applications of deep learning in real life problems. The omnipresent
availability of historical image material and the use of advanced deep learning techniques created a desire
to use written of image data in a new way. Since resolution in historical image data is often very limited
researchers have developed Generative Adversarial Network (GAN) models to increase resolution in order to make old
data usable. In this report we describe our approach on recreating a GAN for image super resolution, heavily
inspired by Ledig et al.~\cite{DBLP:journals/corr/LedigTHCATTWS16}.
\end{abstract}

\section{Motivation}

With TV's and screens getting bigger and an ever increasing resolution the computitional effort to render images for these resolutions rises. Especially in the context of video games, powerful GPU's are needed to render images for high resolutions fast enough. While today most of these graphics cards are really expensive, most of the time they are sold out and it is hard to get a hand on one of them.
A solution to this problem is to render frames in a lower quality and upscale them to a bigger resolution in constant time using a neural network, typically utilizing a GAN architecture. This reduces the time to render frames drastically, which makes it possible to play games on high resolution without the need to buy the most powerful graphics card on the market. 
This technique also proves useful in many other szenarios.
Using upscaling, images with low resolution (e.g. historical data like old fotos or films) can be reprocessed, increasing its usability and esthetic.
Further, data from surveillance cameras, which typically come at a low resolution, especially when they are older, can be made more useful, as details are increased. Therefore it can be also used to help in crime investigation, especially with further postprocessing steps, like face or object recognition.
In the following, we describe our recreation of the approach proposed by Ledig et al. \cite{DBLP:journals/corr/LedigTHCATTWS16}. 

\section{Method}
\subsection{Network architecture}
The network architecture shown in figure~\ref{fig:network_architecture} is also heavily inspired by Ledit et al.~\cite{DBLP:journals/corr/LedigTHCATTWS16}.\\
The generator starts by utilizing a convolutional layer activated by PReLU. 
After that, it is followed by a series of residual blocks, 
which aim to remember the input of the network. 
After another convolutional layer the input will be added to the current state by a skip connection spanning over all residual blocks. 
Finally, the network uses a series of upscaling blocks, consisting of convolutional and conv. transpose layers followed by PReLU activation to perform the actuall upscaling process. 
Afterwards, another convolutional layer will be applied and generate the output image. The generator tries to recreate the full resolution image as exactly as possible from the low resolution image it gets as an input.

The discriminator starts with the same convolutional layers as the generator, activated by Leaky ReLU instead of PReLU. 
Afterwards it is followed by a series of convolution, batch normalization and Leaky ReLU activation blocks, varying in number of channels and stride size. 
Finally the images will run through a dense layer with the size of 1024, activated by Leaky ReLU and a dense layer of size 1, activated by Sigmoid. 
The discriminator then decides whether the input image was upscaled by the generator or is an original full resolution image.

All convolutional layers are described by a code consisting of k (kernel size), n (number of blocks) and s (stride size). Example: k9-n64-s1 describes a layer with a kernel size of 9x9, 64 channels and a stride of 1.

\begin{center}
    \begin{figure}[h] 
        \includegraphics[scale=0.7]{../images/gen_and_dis.pdf}  
        \caption{Generator and Discriminator Network similar to Ledig et al.~\cite{DBLP:journals/corr/LedigTHCATTWS16} }   
        \label{fig:network_architecture}
    \end{figure} 
\end{center}


\subsection{Dataset}
We use the Common Objects in Context Dataset (COCO) by Microsoft~\cite{lin2015microsoft}.
\section{Experiments}
TODO

\section*{Discussion}
TODO

\section*{Conclusion}
TODO


\bibliographystyle{ieeetr}
\bibliography{references}

\end{document}
